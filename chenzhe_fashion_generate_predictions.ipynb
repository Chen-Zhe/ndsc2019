{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_path as fp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import collections\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemid : unique values = 275142 , non-empty rows = 275142\n",
      "title : unique values = 241693 , non-empty rows = 275142\n",
      "image_path : unique values = 275142 , non-empty rows = 275142\n",
      "Pattern : unique values = 21 , non-empty rows = 164078\n",
      "Collar Type : unique values = 17 , non-empty rows = 113638\n",
      "Fashion Trend : unique values = 12 , non-empty rows = 147084\n",
      "Clothing Material : unique values = 20 , non-empty rows = 175499\n",
      "Sleeves : unique values = 5 , non-empty rows = 177903\n"
     ]
    }
   ],
   "source": [
    "input_data = pd.read_csv(fp.csv_folder+\"fashion_data_info_train_competition.csv\")\n",
    "validation_data = pd.read_csv(fp.csv_folder+\"fashion_data_info_val_competition.csv\")\n",
    "\n",
    "for col in input_data.columns.values:\n",
    "    print(col, \": unique values =\", len(input_data[col].unique()), \", non-empty rows =\", len(input_data.dropna(subset=[col])))\n",
    "\n",
    "# convert floating points class types to integer. Empty class type is filled with -1\n",
    "input_data[input_data.columns.values[3:]] = input_data[input_data.columns.values[3:]].fillna(-1.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add image features to validation data\n",
    "resnet_features = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', pooling=\"avg\")\n",
    "\n",
    "def get_resnet_features(image_path):\n",
    "  try:\n",
    "    im = cv2.resize(cv2.imread(fp.image_base_folder+image_path), (224, 224)).astype(np.float32)\n",
    "    # standardization: remove mean of ISLVRC2012 dataset\n",
    "    im[:,:,0] -= 103.939\n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    # Insert a new dimension for the batch_size\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return resnet_features.predict(im)[0]\n",
    "  except:\n",
    "    return None\n",
    "\n",
    "validation_data[\"image_vector\"] = validation_data.apply(lambda x: get_resnet_features(x.image_path), axis=1)\n",
    "input_data[\"image_vector\"] = input_data.apply(lambda x: get_resnet_features(x.image_path), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add image features to validation data\n",
    "resnet_features = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', pooling=\"avg\")\n",
    "\n",
    "def get_resnet_features(image_path, vec):\n",
    "  try:\n",
    "#     if image_path[-4:] != \".jpg\":\n",
    "#       image_path += \".jpg\"\n",
    "    if vec is None:\n",
    "      image_path += \".jpg\"\n",
    "    else:\n",
    "      return vec\n",
    "      \n",
    "    im = cv2.resize(cv2.imread(fp.image_base_folder+image_path), (224, 224)).astype(np.float32)\n",
    "    # standardization: remove mean of ISLVRC2012 dataset\n",
    "    im[:,:,0] -= 103.939\n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    # Insert a new dimension for the batch_size\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return resnet_features.predict(im)[0]\n",
    "  except:\n",
    "    return None \n",
    "  \n",
    "input_data[\"image_vector\"] = input_data.apply(l  ambda x: get_resnet_features(x.image_path, x.image_vector), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.to_pickle(fp.csv_folder+\"fashion_training_with_resnet50_vector_and_word2vec.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.to_pickle(fp.csv_folder+\"fashion_validation_with_resnet50_vector_and_word2vec.pickle\")\n",
    "input_data.to_pickle(fp.csv_folder+\"fashion_training_with_resnet50_vector_and_word2vec.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_pickle(fp.csv_folder+\"fashion_training_with_resnet50_vector_and_word2vec.pickle\")\n",
    "validation_data = pd.read_pickle(fp.csv_folder+\"fashion_validation_with_resnet50_vector_and_word2vec.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_phone_number(string):\n",
    "  if len(string) <= 3:\n",
    "    return False\n",
    "  digit_count = 0\n",
    "  for char in string:\n",
    "    if char.isdigit():\n",
    "      digit_count += 1\n",
    "      \n",
    "  if digit_count > 3:\n",
    "    return True\n",
    "  \n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 3826002\n"
     ]
    }
   ],
   "source": [
    "vocab_sentence = list()\n",
    "sentence_id = 0\n",
    "\n",
    "for line in np.concatenate([input_data.title.values, validation_data.title.values]):\n",
    "  tokens = line.split()\n",
    "  for token in tokens:\n",
    "    # remove telephone numbers\n",
    "    if len(token) == 1 and not token.isdigit():\n",
    "      continue\n",
    "    if is_phone_number(token):\n",
    "      continue\n",
    "    if token == \"whatsapp\" or token == \"wa\":\n",
    "      continue\n",
    "      \n",
    "    vocab_sentence.append((token, sentence_id))\n",
    "  \n",
    "  sentence_id += 1\n",
    "\n",
    "vocabulary, sentence_id_map = list(zip(*vocab_sentence))\n",
    "  \n",
    "print('Data size', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words [('lengan', 180189), ('wanita', 141374), ('dress', 122219), ('neck', 100857), ('untuk', 97713)]\n",
      "Sample data [88, 46, 3, 3, 46, 37, 78, 114, 75, 169] ['retro', 'floral', 'dress', 'dress', 'floral', 'sifon', 'korean', 'white', 'chiffon', 'collar']\n",
      "length of the dictionary:  400 should be equal to 400\n",
      "least common words [('belahan', 834), ('bralette', 824), ('tembus', 822), ('two', 814), ('belakang', 810)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "vocabulary_size = 400\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "  \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    index = dictionary.get(word, 0)\n",
    "    if index == 0:  # dictionary['UNK']\n",
    "      unk_count += 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "  return data, count, dictionary, reversed_dictionary\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(vocabulary, vocabulary_size)\n",
    "# del vocabulary  # Hint to reduce memory.\n",
    "print('Most common words', count[1:6])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])\n",
    "print(\"length of the dictionary: \", len(reverse_dictionary), \"should be equal to\", vocabulary_size)\n",
    "print(\"least common words\", count[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Term Frequency - Inverse Term Frequency for most common words\n",
    "known_word_set = set([word for word, _ in count[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['retro floral dress' 'dress floral sifon']\n",
      "3 dress -> 46 floral\n",
      "0 UNK -> 0 UNK\n",
      "3 dress -> 37 sifon\n",
      "3 dress -> 46 floral\n",
      "0 UNK -> 0 UNK\n",
      "46 floral -> 3 dress\n",
      "37 sifon -> 46 floral\n",
      "0 UNK -> 0 UNK\n",
      "0 UNK -> 0 UNK\n",
      "78 korean -> 114 white\n",
      "0 UNK -> 0 UNK\n",
      "114 white -> 169 collar\n",
      "75 chiffon -> 114 white\n",
      "75 chiffon -> 78 korean\n",
      "0 UNK -> 0 UNK\n",
      "169 collar -> 75 chiffon\n",
      "3 dress -> 169 collar\n",
      "0 UNK -> 0 UNK\n",
      "18 women -> 0 UNK\n",
      "0 UNK -> 0 UNK\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "# new\n",
    "# Step 3: Function to generate a training batch for the skip-gram model.\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "  global data_index\n",
    "  assert batch_size % num_skips == 0\n",
    "  assert num_skips <= 2 * skip_window\n",
    "  batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "  labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "  span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "  buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
    "  if data_index + span > len(data):\n",
    "      data_index = 0\n",
    "  buffer.extend(data[data_index:data_index + span])\n",
    "  data_index += span\n",
    "  for i in range(batch_size // num_skips):\n",
    "    context_words = [w for w in range(span) if w != skip_window]\n",
    "    words_to_use = random.sample(context_words, num_skips)\n",
    "    for j, context_word in enumerate(words_to_use):\n",
    "      if sentence_id_map[data_index-span+skip_window] == sentence_id_map[data_index-span+context_word]:\n",
    "        batch[i * num_skips + j] = buffer[skip_window]\n",
    "        labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "      else:\n",
    "        batch[i * num_skips + j] = 0\n",
    "        labels[i * num_skips + j, 0] = 0\n",
    "    if data_index == len(data):\n",
    "      buffer.extend(data[0:span])\n",
    "      data_index = span\n",
    "    else:\n",
    "      buffer.append(data[data_index])\n",
    "      data_index += 1\n",
    "  # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "  data_index = (data_index + len(data) - span) % len(data)\n",
    "  return batch, labels\n",
    "\n",
    "batch, labels = generate_batch(batch_size=20, num_skips=2, skip_window=2)\n",
    "print(input_data.title.head(2).values)\n",
    "for i in range(20):\n",
    "  print(batch[i], reverse_dictionary[batch[i]], '->', labels[i, 0], reverse_dictionary[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build and train a skip-gram model.\n",
    "\n",
    "batch_size = 128\n",
    "embedding_size = 64  # Dimension of the embedding vector.\n",
    "skip_window = 1  # How many words to consider left and right.\n",
    "num_skips = 2  # How many times to reuse an input to generate a label.\n",
    "num_sampled = 64  # Number of negative examples to sample.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent. These 3 variables are used only for\n",
    "# displaying model accuracy, they don't affect calculation.\n",
    "valid_size = 16  # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  with tf.name_scope('inputs'):\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    # Look up embeddings for inputs.\n",
    "  with tf.name_scope('embeddings'):\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "# Construct the variables for the NCE loss\n",
    "  with tf.name_scope('weights'):\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size))\n",
    "    )\n",
    "  with tf.name_scope('biases'):\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "  # Compute the average NCE loss for the batch.\n",
    "  # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "  # time we evaluate the loss.\n",
    "  # Explanation of the meaning of NCE loss:\n",
    "  #   http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "  with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(\n",
    "            weights=nce_weights,\n",
    "            biases=nce_biases,\n",
    "            labels=train_labels,\n",
    "            inputs=embed,\n",
    "            num_sampled=num_sampled,\n",
    "            num_classes=vocabulary_size))\n",
    "\n",
    "  # Add the loss value as a scalar to summary.\n",
    "  tf.summary.scalar('loss', loss)\n",
    "\n",
    "  # Construct the SGD optimizer\n",
    "  with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "  # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "  normalized_embeddings = embeddings / norm\n",
    "  valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,\n",
    "                                            valid_dataset)\n",
    "  similarity = tf.matmul(\n",
    "      valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "  # Merge all summaries.\n",
    "  merged = tf.summary.merge_all()\n",
    "\n",
    "  # Add variable initializer.\n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  # Create a saver.\n",
    "#   saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps to run: 597820\n",
      "Initialized\n",
      "Average loss at step 0 : 118.23272705078125\n",
      "Average loss at step 2000 : 41.563430080890654\n",
      "Average loss at step 4000 : 12.507865993499756\n",
      "Average loss at step 6000 : 8.232627920150756\n",
      "Average loss at step 8000 : 6.63601957499981\n",
      "Average loss at step 10000 : 5.828361275911331\n",
      "Average loss at step 12000 : 5.299916382312775\n",
      "Average loss at step 14000 : 5.003721959590912\n",
      "Average loss at step 16000 : 4.778860801815987\n",
      "Average loss at step 18000 : 4.63048234963417\n",
      "Average loss at step 20000 : 4.508250107765198\n",
      "Average loss at step 22000 : 4.586850935339927\n",
      "Average loss at step 24000 : 4.829594003200531\n",
      "Average loss at step 26000 : 4.500870619297028\n",
      "Average loss at step 28000 : 4.374320547699928\n",
      "Average loss at step 30000 : 4.273100596547127\n",
      "Average loss at step 32000 : 4.201676884174347\n",
      "Average loss at step 34000 : 4.162560703158379\n",
      "Average loss at step 36000 : 4.129571531176567\n",
      "Average loss at step 38000 : 4.097367225527764\n",
      "Average loss at step 40000 : 4.070415989756584\n",
      "Average loss at step 42000 : 4.0376535811424255\n",
      "Average loss at step 44000 : 4.016876212000847\n",
      "Average loss at step 46000 : 4.002084624290466\n",
      "Average loss at step 48000 : 3.9740539454221726\n",
      "Average loss at step 50000 : 3.8601327340602873\n",
      "Average loss at step 52000 : 3.844526218533516\n",
      "Average loss at step 54000 : 3.963777645111084\n",
      "Average loss at step 56000 : 4.036046609997749\n",
      "Average loss at step 58000 : 3.9604812290668487\n",
      "Average loss at step 60000 : 3.9275171921253205\n",
      "Average loss at step 62000 : 4.017369754314423\n",
      "Average loss at step 64000 : 3.982787266731262\n",
      "Average loss at step 66000 : 3.9724362725019455\n",
      "Average loss at step 68000 : 3.9585513882637025\n",
      "Average loss at step 70000 : 3.9537656981945037\n",
      "Average loss at step 72000 : 3.9404734674692152\n",
      "Average loss at step 74000 : 3.935463666558266\n",
      "Average loss at step 76000 : 3.9293146811723707\n",
      "Average loss at step 78000 : 3.9177144048213957\n",
      "Average loss at step 80000 : 3.916780743598938\n",
      "Average loss at step 82000 : 3.970819672703743\n",
      "Average loss at step 84000 : 4.003656926035881\n",
      "Average loss at step 86000 : 3.9322083715200424\n",
      "Average loss at step 88000 : 3.9151985387802126\n",
      "Average loss at step 90000 : 3.893183172464371\n",
      "Average loss at step 92000 : 3.880435922384262\n",
      "Average loss at step 94000 : 3.8713836197853086\n",
      "Average loss at step 96000 : 3.874975944161415\n",
      "Average loss at step 98000 : 3.86479472219944\n",
      "Average loss at step 100000 : 3.854146985054016\n",
      "Average loss at step 102000 : 3.8419836572408674\n",
      "Average loss at step 104000 : 3.835312870621681\n",
      "Average loss at step 106000 : 3.8341800318956376\n",
      "Average loss at step 108000 : 3.7794558655023573\n",
      "Average loss at step 110000 : 3.7096775584220887\n",
      "Average loss at step 112000 : 3.7043659143447876\n",
      "Average loss at step 114000 : 3.8394709483385085\n",
      "Average loss at step 116000 : 3.85657684803009\n",
      "Average loss at step 118000 : 3.8140975219011306\n",
      "Average loss at step 120000 : 3.813010694026947\n",
      "Average loss at step 122000 : 3.893244091629982\n",
      "Average loss at step 124000 : 3.8687581741809844\n",
      "Average loss at step 126000 : 3.8583728224039078\n",
      "Average loss at step 128000 : 3.856184475183487\n",
      "Average loss at step 130000 : 3.853391352534294\n",
      "Average loss at step 132000 : 3.840601845741272\n",
      "Average loss at step 134000 : 3.8470720262527465\n",
      "Average loss at step 136000 : 3.835073070645332\n",
      "Average loss at step 138000 : 3.8303615359067917\n",
      "Average loss at step 140000 : 3.8297966160774233\n",
      "Average loss at step 142000 : 3.8979631891250612\n",
      "Average loss at step 144000 : 3.8938048702478407\n",
      "Average loss at step 146000 : 3.8368290390968323\n",
      "Average loss at step 148000 : 3.8311307616233825\n",
      "Average loss at step 150000 : 3.811646672964096\n",
      "Average loss at step 152000 : 3.7986243376731874\n",
      "Average loss at step 154000 : 3.7999024028778075\n",
      "Average loss at step 156000 : 3.7973896222114565\n",
      "Average loss at step 158000 : 3.7930773409605028\n",
      "Average loss at step 160000 : 3.7857042939662935\n",
      "Average loss at step 162000 : 3.7750027017593384\n",
      "Average loss at step 164000 : 3.770662235379219\n",
      "Average loss at step 166000 : 3.771544871687889\n",
      "Average loss at step 168000 : 3.7000457264184954\n",
      "Average loss at step 170000 : 3.647041654109955\n",
      "Average loss at step 172000 : 3.6436620371341704\n",
      "Average loss at step 174000 : 3.7980549845695495\n",
      "Average loss at step 176000 : 3.782868127703667\n",
      "Average loss at step 178000 : 3.7497519624233244\n",
      "Average loss at step 180000 : 3.766628989696503\n",
      "Average loss at step 182000 : 3.8377929751873014\n",
      "Average loss at step 184000 : 3.812254073023796\n",
      "Average loss at step 186000 : 3.805300418496132\n",
      "Average loss at step 188000 : 3.801329230666161\n",
      "Average loss at step 190000 : 3.801764808893204\n",
      "Average loss at step 192000 : 3.7984636929035185\n",
      "Average loss at step 194000 : 3.7965897183418273\n",
      "Average loss at step 196000 : 3.7868363559246063\n",
      "Average loss at step 198000 : 3.783274409651756\n",
      "Average loss at step 200000 : 3.787410011649132\n",
      "Average loss at step 202000 : 3.864235844135284\n",
      "Average loss at step 204000 : 3.8316142514944076\n",
      "Average loss at step 206000 : 3.7869562976360323\n",
      "Average loss at step 208000 : 3.780531045794487\n",
      "Average loss at step 210000 : 3.766697477579117\n",
      "Average loss at step 212000 : 3.753283937335014\n",
      "Average loss at step 214000 : 3.753172674179077\n",
      "Average loss at step 216000 : 3.756049135327339\n",
      "Average loss at step 218000 : 3.7527202316522597\n",
      "Average loss at step 220000 : 3.7475810515880585\n",
      "Average loss at step 222000 : 3.730351647853851\n",
      "Average loss at step 224000 : 3.733910022139549\n",
      "Average loss at step 226000 : 3.7363362900018693\n",
      "Average loss at step 228000 : 3.648031789064407\n",
      "Average loss at step 230000 : 3.6149573051929473\n",
      "Average loss at step 232000 : 3.606664718866348\n",
      "Average loss at step 234000 : 3.777898921132088\n",
      "Average loss at step 236000 : 3.7388248637914656\n",
      "Average loss at step 238000 : 3.709702742099762\n",
      "Average loss at step 240000 : 3.7430662454366685\n",
      "Average loss at step 242000 : 3.7965059225559235\n",
      "Average loss at step 244000 : 3.7799450068473814\n",
      "Average loss at step 246000 : 3.76930839073658\n",
      "Average loss at step 248000 : 3.76980955517292\n",
      "Average loss at step 250000 : 3.7657670960426333\n",
      "Average loss at step 252000 : 3.7647309960126876\n",
      "Average loss at step 254000 : 3.7649144294261934\n",
      "Average loss at step 256000 : 3.758817554116249\n",
      "Average loss at step 258000 : 3.7478712120056152\n",
      "Average loss at step 260000 : 3.755535037279129\n",
      "Average loss at step 262000 : 3.840533675312996\n",
      "Average loss at step 264000 : 3.7874690264463426\n",
      "Average loss at step 266000 : 3.756115147471428\n",
      "Average loss at step 268000 : 3.746340698838234\n",
      "Average loss at step 270000 : 3.7329371358156203\n",
      "Average loss at step 272000 : 3.727241615653038\n",
      "Average loss at step 274000 : 3.7245771032571793\n",
      "Average loss at step 276000 : 3.729448756933212\n",
      "Average loss at step 278000 : 3.7254207558631895\n",
      "Average loss at step 280000 : 3.712567244887352\n",
      "Average loss at step 282000 : 3.7040441294908524\n",
      "Average loss at step 284000 : 3.7014475154876707\n",
      "Average loss at step 286000 : 3.7059458812475206\n",
      "Average loss at step 288000 : 3.614665310263634\n",
      "Average loss at step 290000 : 3.5853143525123596\n",
      "Average loss at step 292000 : 3.5870890592336653\n",
      "Average loss at step 294000 : 3.761293078303337\n",
      "Average loss at step 296000 : 3.705263916730881\n",
      "Average loss at step 298000 : 3.6801679577827455\n",
      "Average loss at step 300000 : 3.7320298784971238\n",
      "Average loss at step 302000 : 3.7680451810359954\n",
      "Average loss at step 304000 : 3.7558988938331606\n",
      "Average loss at step 306000 : 3.744242275953293\n",
      "Average loss at step 308000 : 3.74590124464035\n",
      "Average loss at step 310000 : 3.7437801152467727\n",
      "Average loss at step 312000 : 3.741519804596901\n",
      "Average loss at step 314000 : 3.735834606051445\n",
      "Average loss at step 316000 : 3.738221643805504\n",
      "Average loss at step 318000 : 3.726401284813881\n",
      "Average loss at step 320000 : 3.7360141932964326\n",
      "Average loss at step 322000 : 3.821772810459137\n",
      "Average loss at step 324000 : 3.75967127263546\n",
      "Average loss at step 326000 : 3.731244558572769\n",
      "Average loss at step 328000 : 3.721483837723732\n",
      "Average loss at step 330000 : 3.711023402810097\n",
      "Average loss at step 332000 : 3.7052000975608825\n",
      "Average loss at step 334000 : 3.7070412113666533\n",
      "Average loss at step 336000 : 3.7062110426425936\n",
      "Average loss at step 338000 : 3.70284904050827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 340000 : 3.693199078083038\n",
      "Average loss at step 342000 : 3.6892893110513687\n",
      "Average loss at step 344000 : 3.6819405633211137\n",
      "Average loss at step 346000 : 3.687534215450287\n",
      "Average loss at step 348000 : 3.5831584013700484\n",
      "Average loss at step 350000 : 3.5655936866998674\n",
      "Average loss at step 352000 : 3.5745895270109176\n",
      "Average loss at step 354000 : 3.748481830239296\n",
      "Average loss at step 356000 : 3.6810733872652053\n",
      "Average loss at step 358000 : 3.656140588283539\n",
      "Average loss at step 360000 : 3.7237858241796493\n",
      "Average loss at step 362000 : 3.7513633850812913\n",
      "Average loss at step 364000 : 3.735221441268921\n",
      "Average loss at step 366000 : 3.7264431278705596\n",
      "Average loss at step 368000 : 3.7278698773384096\n",
      "Average loss at step 370000 : 3.7258115334510804\n",
      "Average loss at step 372000 : 3.723586210131645\n",
      "Average loss at step 374000 : 3.7223733518123625\n",
      "Average loss at step 376000 : 3.7164123785495757\n",
      "Average loss at step 378000 : 3.711483700990677\n",
      "Average loss at step 380000 : 3.7176148869991303\n",
      "Average loss at step 382000 : 3.8067579251527786\n",
      "Average loss at step 384000 : 3.7383504128456115\n",
      "Average loss at step 386000 : 3.710949516415596\n",
      "Average loss at step 388000 : 3.7058759053945542\n",
      "Average loss at step 390000 : 3.695293011069298\n",
      "Average loss at step 392000 : 3.687012270092964\n",
      "Average loss at step 394000 : 3.688821328639984\n",
      "Average loss at step 396000 : 3.6892952548265456\n",
      "Average loss at step 398000 : 3.688418107748032\n",
      "Average loss at step 400000 : 3.67598564517498\n",
      "Average loss at step 402000 : 3.668326441168785\n",
      "Average loss at step 404000 : 3.669796421289444\n",
      "Average loss at step 406000 : 3.6697221813201906\n",
      "Average loss at step 408000 : 3.5557349578142166\n",
      "Average loss at step 410000 : 3.552562775850296\n",
      "Average loss at step 412000 : 3.5753037900924682\n",
      "Average loss at step 414000 : 3.740312497019768\n",
      "Average loss at step 416000 : 3.6589700288772584\n",
      "Average loss at step 418000 : 3.6445073676109314\n",
      "Average loss at step 420000 : 3.7223642983436585\n",
      "Average loss at step 422000 : 3.733722311496735\n",
      "Average loss at step 424000 : 3.714602091908455\n",
      "Average loss at step 426000 : 3.7128722323179244\n",
      "Average loss at step 428000 : 3.7129364520311356\n",
      "Average loss at step 430000 : 3.710886762261391\n",
      "Average loss at step 432000 : 3.710616602420807\n",
      "Average loss at step 434000 : 3.7043320314884185\n",
      "Average loss at step 436000 : 3.7025670703649523\n",
      "Average loss at step 438000 : 3.7006869344711304\n",
      "Average loss at step 440000 : 3.7046994627714156\n",
      "Average loss at step 442000 : 3.79950540304184\n",
      "Average loss at step 444000 : 3.7135279673337935\n",
      "Average loss at step 446000 : 3.7003242824077605\n",
      "Average loss at step 448000 : 3.689595304489136\n",
      "Average loss at step 450000 : 3.6755076971054077\n",
      "Average loss at step 452000 : 3.6762353522777556\n",
      "Average loss at step 454000 : 3.679215155005455\n",
      "Average loss at step 456000 : 3.673750767827034\n",
      "Average loss at step 458000 : 3.678819579958916\n",
      "Average loss at step 460000 : 3.656216812372208\n",
      "Average loss at step 462000 : 3.662410262942314\n",
      "Average loss at step 464000 : 3.6590324212312697\n",
      "Average loss at step 466000 : 3.651026809811592\n",
      "Average loss at step 468000 : 3.539172228693962\n",
      "Average loss at step 470000 : 3.536848777770996\n",
      "Average loss at step 472000 : 3.5803220685720443\n",
      "Average loss at step 474000 : 3.7206467992067336\n",
      "Average loss at step 476000 : 3.6471954329013823\n",
      "Average loss at step 478000 : 3.6322579255104066\n",
      "Average loss at step 480000 : 3.720765594482422\n",
      "Average loss at step 482000 : 3.7190518938302994\n",
      "Average loss at step 484000 : 3.702866983771324\n",
      "Average loss at step 486000 : 3.6983535388708115\n",
      "Average loss at step 488000 : 3.7025255814790725\n",
      "Average loss at step 490000 : 3.7011203330755236\n",
      "Average loss at step 492000 : 3.6952834206819536\n",
      "Average loss at step 494000 : 3.6915609447956084\n",
      "Average loss at step 496000 : 3.6902100570201872\n",
      "Average loss at step 498000 : 3.689974079608917\n",
      "Average loss at step 500000 : 3.7028093988895416\n",
      "Average loss at step 502000 : 3.7775757278203965\n",
      "Average loss at step 504000 : 3.6948540551662443\n",
      "Average loss at step 506000 : 3.693429523229599\n",
      "Average loss at step 508000 : 3.6722756785154345\n",
      "Average loss at step 510000 : 3.6657730740308763\n",
      "Average loss at step 512000 : 3.66462973177433\n",
      "Average loss at step 514000 : 3.6675447292327883\n",
      "Average loss at step 516000 : 3.6615079288482666\n",
      "Average loss at step 518000 : 3.672413040161133\n",
      "Average loss at step 520000 : 3.6439187264442445\n",
      "Average loss at step 522000 : 3.6518039675951006\n",
      "Average loss at step 524000 : 3.6498743938207627\n",
      "Average loss at step 526000 : 3.6251716747283935\n",
      "Average loss at step 528000 : 3.53205040705204\n",
      "Average loss at step 530000 : 3.5306740437746047\n",
      "Average loss at step 532000 : 3.597590671300888\n",
      "Average loss at step 534000 : 3.6879047644138336\n",
      "Average loss at step 536000 : 3.641294142961502\n",
      "Average loss at step 538000 : 3.615000596046448\n",
      "Average loss at step 540000 : 3.7229194666147234\n",
      "Average loss at step 542000 : 3.7049028012752534\n",
      "Average loss at step 544000 : 3.6971988792419435\n",
      "Average loss at step 546000 : 3.6858461927175523\n",
      "Average loss at step 548000 : 3.6905699355602266\n",
      "Average loss at step 550000 : 3.69047112929821\n",
      "Average loss at step 552000 : 3.685590110182762\n",
      "Average loss at step 554000 : 3.6815800511837007\n",
      "Average loss at step 556000 : 3.686914975166321\n",
      "Average loss at step 558000 : 3.6824884678125382\n",
      "Average loss at step 560000 : 3.7122454673051832\n",
      "Average loss at step 562000 : 3.7487999774217604\n",
      "Average loss at step 564000 : 3.6874970217943193\n",
      "Average loss at step 566000 : 3.6789463332891463\n",
      "Average loss at step 568000 : 3.660695764064789\n",
      "Average loss at step 570000 : 3.6562963443994523\n",
      "Average loss at step 572000 : 3.656113207936287\n",
      "Average loss at step 574000 : 3.661410425543785\n",
      "Average loss at step 576000 : 3.6574894748926163\n",
      "Average loss at step 578000 : 3.6513713768720626\n",
      "Average loss at step 580000 : 3.642128829717636\n",
      "Average loss at step 582000 : 3.639001023054123\n",
      "Average loss at step 584000 : 3.6395738986730577\n",
      "Average loss at step 586000 : 3.60405909717083\n",
      "Average loss at step 588000 : 3.5240062291622163\n",
      "Average loss at step 590000 : 3.5216018624305727\n",
      "Average loss at step 592000 : 3.617500030875206\n",
      "Average loss at step 594000 : 3.671147897839546\n",
      "Average loss at step 596000 : 3.6237139084339143\n",
      "Nearest to panas: gugur, semi, harajuku, 3d, sale, girl, untuk, bow\n",
      "Nearest to baju: large, terbaru, seller, ld, xl, UNK, pakaian, korean\n",
      "Nearest to wanita: kancing, kupu, pantai, two, oversize, baju, seller, kaos\n",
      "Nearest to blouse: cantik, romper, prom, full, half, kekinian, pensil, polka\n",
      "Nearest to vintage: preloved, patchwork, potongan, harga, backless, boho, strip, jersey\n",
      "Nearest to cotton: beach, cewe, womens, pullover, promo, ready, bayar, black\n",
      "Nearest to bunga: seller, kerja, maroon, rumbai, garis, kotak, stretch, two\n",
      "Nearest to bodycon: bandage, low, deep, pullover, mini, branded, line, tanpa\n",
      "Nearest to pesta: patchwork, leher, polkadot, lucu, version, club, atasan, beludru\n",
      "Nearest to malam: pantai, seller, club, gaun, girl, pocket, white, musim\n",
      "Nearest to tank: di, sweater, limited, thin, long, hot, with, pencil\n",
      "Nearest to tempat: crochet, plaid, party, mix, potongan, bralette, women, ld\n",
      "Nearest to import: one, setelan, brukat, silk, salur, tumblr, hip, version\n",
      "Nearest to print: gaya, salur, dot, maroon, bordir, kancing, garis, oversize\n",
      "Nearest to potongan: maroon, pendek, crew, jahitan, midi, vintage, eropa, pita\n",
      "Nearest to gaun: crochet, kantor, hip, kekinian, prom, malam, plaid, party\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Begin training.\n",
    "data_index = 0\n",
    "\n",
    "num_epochs = 10\n",
    "num_steps = (len(data) * num_skips // batch_size + 1) * num_epochs\n",
    "print(\"Steps to run:\", num_steps)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "#   Open a writer to write summaries.\n",
    "#   writer = tf.summary.FileWriter(fp.log_dir, session.graph)\n",
    "\n",
    "  # We must initialize all variables before we use them.\n",
    "  init.run()\n",
    "  print('Initialized')\n",
    "\n",
    "  average_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batch_inputs, batch_labels = generate_batch(batch_size, num_skips,\n",
    "                                                skip_window)\n",
    "    feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "\n",
    "    # Define metadata variable.\n",
    "    run_metadata = tf.RunMetadata()\n",
    "\n",
    "    # We perform one update step by evaluating the optimizer op (including it\n",
    "    # in the list of returned values for session.run()\n",
    "    # Also, evaluate the merged op to get all summaries from the returned \"summary\" variable.\n",
    "    # Feed metadata variable to session for visualizing the graph in TensorBoard.\n",
    "    _, summary, loss_val = session.run(\n",
    "        [optimizer, merged, loss],\n",
    "        feed_dict=feed_dict,\n",
    "        run_metadata=run_metadata)\n",
    "    average_loss += loss_val\n",
    "\n",
    "    # Add returned summaries to writer in each step.\n",
    "#     writer.add_summary(summary, step)\n",
    "    # Add metadata to visualize the graph for the last run.\n",
    "#     if step == (num_steps - 1):\n",
    "#       writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "\n",
    "    if step % 2000 == 0:\n",
    "      if step > 0:\n",
    "        average_loss /= 2000\n",
    "      # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "      print('Average loss at step', step, ':', average_loss)\n",
    "      average_loss = 0\n",
    "\n",
    "    # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "#     if step % 10000 == 0:\n",
    "#       sim = similarity.eval()\n",
    "#       for i in range(valid_size):\n",
    "#         valid_word = reverse_dictionary[valid_examples[i]]\n",
    "#         top_k = 8  # number of nearest neighbors\n",
    "#         nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "#         log_str = 'Nearest to %s: %s' % (valid_word, \", \".join([reverse_dictionary[k] for k in nearest]))\n",
    "#         print(log_str)\n",
    "  \n",
    "  sim = similarity.eval()\n",
    "  for i in range(valid_size):\n",
    "    valid_word = reverse_dictionary[valid_examples[i]]\n",
    "    top_k = 8  # number of nearest neighbors\n",
    "    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "    log_str = 'Nearest to %s: %s' % (valid_word, \", \".join([reverse_dictionary[k] for k in nearest]))\n",
    "    print(log_str)\n",
    "  final_embeddings = normalized_embeddings.eval()\n",
    "\n",
    "  # Write corresponding labels for the embeddings.\n",
    "#   with open(fp.log_dir + '/metadata.tsv', 'w') as f:\n",
    "#     for i in range(vocabulary_size):\n",
    "#       f.write(reverse_dictionary[i] + '\\n')\n",
    "\n",
    "  # Save the model for checkpoints.\n",
    "#   saver.save(session, os.path.join(fp.log_dir, 'model.ckpt'))\n",
    "\n",
    "  # Create a configuration for visualizing embeddings with the labels in TensorBoard.\n",
    "#   config = projector.ProjectorConfig()\n",
    "#   embedding_conf = config.embeddings.add()\n",
    "#   embedding_conf.tensor_name = embeddings.name\n",
    "#   embedding_conf.metadata_path = os.path.join(fp.log_dir, 'metadata.tsv')\n",
    "#   projector.visualize_embeddings(writer, config)\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_title_vector(itemid, title):\n",
    "  tokens = title.split()\n",
    "  total_score = 0.0\n",
    "  total_vec = np.zeros(embedding_size)\n",
    "  for token in tokens:\n",
    "    if token not in known_word_set:\n",
    "      continue\n",
    "    word_vec = final_embeddings[dictionary[token]]\n",
    "    tf_idf_score = 1.0\n",
    "    total_score += tf_idf_score\n",
    "    total_vec += word_vec * tf_idf_score\n",
    "  \n",
    "  if total_score == 0.0:\n",
    "    return total_vec\n",
    "  return total_vec / total_score\n",
    "\n",
    "input_data[\"title_vector\"] = input_data.apply(lambda x: get_avg_title_vector(x.itemid, x.title), axis=1)\n",
    "validation_data[\"title_vector\"] = validation_data.apply(lambda x: get_avg_title_vector(x.itemid, x.title), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(guesses, correct, k):\n",
    "  for i in range(k):\n",
    "    if guesses[i] == correct:\n",
    "      return 1 / (i + 1), i + 1\n",
    "  return 0.0, 0\n",
    "\n",
    "def proba_to_guesses(probs, classes, k):\n",
    "  ret = list()\n",
    "  \n",
    "  for idx in np.argsort(probs)[-k:]:\n",
    "    ret.append(classes[idx])\n",
    "  \n",
    "  ret.reverse()\n",
    "  return ret\n",
    "\n",
    "def score_model(proba_vector, ground_truth, classes, k):\n",
    "  assert proba_vector.shape[1] == len(classes)\n",
    "  assert proba_vector.shape[0] == ground_truth.shape[0]\n",
    "  total_score = 0.0\n",
    "  \n",
    "  stat = [0] * (k + 1)\n",
    "  \n",
    "  for item_vec, correct in zip(proba_vector, ground_truth):\n",
    "    result, idx = map_at_k(proba_to_guesses(item_vec, classes, k), correct, k)\n",
    "    total_score += result\n",
    "    stat[idx] += 1\n",
    "  return total_score / proba_vector.shape[0], stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=64, random_state=12345)\n",
    "\n",
    "reduced_image_vector = pca.fit_transform(np.stack(input_data.image_vector.values))\n",
    "\n",
    "input_data[\"image_vector_64\"] = np.vsplit(reduced_image_vector, indices_or_sections=reduced_image_vector.shape[0])\n",
    "\n",
    "validation_reduced_image_vector = pca.transform(np.stack(validation_data.image_vector.values))\n",
    "\n",
    "validation_data[\"image_vector_64\"] = np.vsplit(validation_reduced_image_vector,\n",
    "                                               indices_or_sections=validation_reduced_image_vector.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern (0.8795099951243296, [3005, 27913, 1898])\n",
      "Collar Type (0.8339933122140092, [2063, 17245, 3420])\n",
      "Fashion Trend (0.8938368970323283, [2104, 25275, 2038])\n"
     ]
    }
   ],
   "source": [
    "#dry run\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for y_col in input_data.columns.values[3:6]:\n",
    "  train, test = train_test_split(input_data[input_data[y_col] != -1], test_size=0.2, random_state=12345)\n",
    "  \n",
    "  if train[y_col].unique().shape[0] > 100:\n",
    "    significant = set(train[[y_col, \"itemid\"]].groupby(y_col).agg(\"count\")\\\n",
    "      .sort_values(\"itemid\", ascending=False).head(100).index.values)\n",
    "    train = train[train.apply(lambda x: x[y_col] in significant, axis=1)]\n",
    "    \n",
    "  clf = RandomForestClassifier(n_estimators=200, random_state=0, n_jobs=-1)\n",
    "  clf.fit(np.concatenate(\n",
    "    (np.stack(train.title_vector.values), np.stack(train.image_vector_64.values).reshape(-1, 64))\n",
    "    , axis=1), train[y_col])\n",
    "  \n",
    "  print(y_col, score_model(\n",
    "    clf.predict_proba(\n",
    "        np.concatenate(\n",
    "        (np.stack(test.title_vector.values), np.stack(test.image_vector_64.values).reshape(-1, 64))\n",
    "        , axis=1)\n",
    "      )\n",
    "      , test[y_col].values, clf.classes_, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern : training model...write to file...\n",
      "Collar Type : training model...write to file...\n",
      "Fashion Trend : training model...write to file...\n",
      "Clothing Material : training model...write to file...\n",
      "Sleeves : training model...write to file...\n"
     ]
    }
   ],
   "source": [
    "# actual run\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(fp.csv_folder+\"submission/fashion_no_header.csv\", \"w\") as sub_file:\n",
    "  for y_col in input_data.columns.values[3:]:\n",
    "    try:\n",
    "      train, test = input_data[input_data[y_col] != -1], validation_data\n",
    "    except:\n",
    "      # there are vector feature fields after y columns\n",
    "      break\n",
    "\n",
    "    if train[y_col].unique().shape[0] > 100:\n",
    "      significant = set(train[[y_col, \"itemid\"]].groupby(y_col).agg(\"count\")\\\n",
    "        .sort_values(\"itemid\", ascending=False).head(100).index.values)\n",
    "      train = train[train.apply(lambda x: x[y_col] in significant, axis=1)]\n",
    "    \n",
    "    print(y_col, \": training model...\", end=\"\")\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=0, n_jobs=-1)\n",
    "    clf.fit(np.concatenate(\n",
    "      (np.stack(train.title_vector.values), np.stack(train.image_vector_64.values).reshape(-1, 64))\n",
    "      , axis=1), train[y_col])\n",
    "\n",
    "    proba_vector = clf.predict_proba(\n",
    "          np.concatenate(\n",
    "          (np.stack(test.title_vector.values), np.stack(test.image_vector_64.values).reshape(-1, 64))\n",
    "          , axis=1)\n",
    "        )\n",
    "    assert validation_data.itemid.values.shape[0] == proba_vector.shape[0]\n",
    "    \n",
    "    print(\"write to file...\")\n",
    "\n",
    "    for itemid, item_vec in zip(validation_data.itemid.values, proba_vector):\n",
    "      guesses = proba_to_guesses(item_vec, clf.classes_, 2)\n",
    "      sub_file.write(f\"{itemid}_{y_col},{' '.join([str(g) for g in guesses])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
