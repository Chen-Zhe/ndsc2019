{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_path as fp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import collections\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(fp.csv_folder+\"beauty_data_info_train_competition.csv\")\n",
    "validation_data = pd.read_csv(fp.csv_folder+\"beauty_data_info_val_competition.csv\")\n",
    "\n",
    "# convert floating points class types to integer. Empty class type is filled with -1\n",
    "input_data[input_data.columns.values[3:]] = input_data[input_data.columns.values[3:]].fillna(-1.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add image features to validation data\n",
    "resnet_features = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', pooling=\"avg\")\n",
    "\n",
    "def get_resnet_features(image_path):\n",
    "  try:\n",
    "    im = cv2.resize(cv2.imread(fp.image_base_folder+image_path), (224, 224)).astype(np.float32)\n",
    "    # standardization: remove mean of ISLVRC2012 dataset\n",
    "    im[:,:,0] -= 103.939\n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    # Insert a new dimension for the batch_size\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return resnet_features.predict(im)[0]\n",
    "  except:\n",
    "    return None\n",
    "\n",
    "validation_data[\"image_vector\"] = validation_data.apply(lambda x: get_resnet_features(x.image_path), axis=1)\n",
    "input_data[\"image_vector\"] = input_data.apply(lambda x: get_resnet_features(x.image_path), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.to_pickle(fp.csv_folder+\"beauty_validation_with_resnet50_vector_and_word2vec.pickle\")\n",
    "input_data.to_pickle(fp.csv_folder+\"beauty_training_with_resnet50_vector_and_word2vec.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_pickle(fp.csv_folder+\"beauty_training_with_resnet50_vector_and_word2vec.pickle\")\n",
    "validation_data = pd.read_pickle(fp.csv_folder+\"beauty_validation_with_resnet50_vector_and_word2vec.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_phone_number(string):\n",
    "  if len(string) <= 3:\n",
    "    return False\n",
    "  digit_count = 0\n",
    "  for char in string:\n",
    "    if char.isdigit():\n",
    "      digit_count += 1\n",
    "      \n",
    "  if digit_count > 3:\n",
    "    return True\n",
    "  \n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 2720660\n"
     ]
    }
   ],
   "source": [
    "vocab_sentence = list()\n",
    "sentence_id = 0\n",
    "\n",
    "for line in np.concatenate([input_data.title.values, validation_data.title.values]):\n",
    "  tokens = line.split()\n",
    "  for token in tokens:\n",
    "    # remove telephone numbers\n",
    "    if len(token) == 1 and not token.isdigit():\n",
    "      continue\n",
    "    if is_phone_number(token):\n",
    "      continue\n",
    "    if token == \"whatsapp\" or token == \"wa\":\n",
    "      continue\n",
    "      \n",
    "    vocab_sentence.append((token, sentence_id))\n",
    "  \n",
    "  sentence_id += 1\n",
    "\n",
    "vocabulary, sentence_id_map = list(zip(*vocab_sentence))\n",
    "  \n",
    "print('Data size', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words [('cream', 98659), ('powder', 65051), ('lip', 53092), ('matte', 52011), ('bb', 37399)]\n",
      "Sample data [24, 0, 0, 0, 14, 136, 15, 23, 151, 39] ['nyx', 'UNK', 'UNK', 'UNK', 'natural', 'palette', 'etude', 'house', 'precious', 'mineral']\n",
      "length of the dictionary:  400 should be equal to 400\n",
      "least common words [('complete', 1154), ('paris', 1150), ('silver', 1150), ('04', 1138), ('illuminating', 1137)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "vocabulary_size = 400\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "  \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    index = dictionary.get(word, 0)\n",
    "    if index == 0:  # dictionary['UNK']\n",
    "      unk_count += 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "  return data, count, dictionary, reversed_dictionary\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(vocabulary, vocabulary_size)\n",
    "# del vocabulary  # Hint to reduce memory.\n",
    "print('Most common words', count[1:6])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])\n",
    "print(\"length of the dictionary: \", len(reverse_dictionary), \"should be equal to\", vocabulary_size)\n",
    "print(\"least common words\", count[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Term Frequency - Inverse Term Frequency for most common words\n",
    "known_word_set = set([word for word, _ in count[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nyx sex bomb pallete natural palette'\n",
      " 'etude house precious mineral any cushion pearl aura puff']\n",
      "0 UNK -> 0 UNK\n",
      "0 UNK -> 0 UNK\n",
      "0 UNK -> 0 UNK\n",
      "0 UNK -> 14 natural\n",
      "0 UNK -> 0 UNK\n",
      "14 natural -> 0 UNK\n",
      "0 UNK -> 0 UNK\n",
      "136 palette -> 14 natural\n",
      "15 etude -> 151 precious\n",
      "0 UNK -> 0 UNK\n",
      "0 UNK -> 0 UNK\n",
      "23 house -> 151 precious\n",
      "151 precious -> 23 house\n",
      "151 precious -> 39 mineral\n",
      "39 mineral -> 23 house\n",
      "39 mineral -> 6 cushion\n",
      "0 UNK -> 0 UNK\n",
      "0 UNK -> 151 precious\n",
      "6 cushion -> 0 UNK\n",
      "6 cushion -> 39 mineral\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "# new\n",
    "# Step 3: Function to generate a training batch for the skip-gram model.\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "  global data_index\n",
    "  assert batch_size % num_skips == 0\n",
    "  assert num_skips <= 2 * skip_window\n",
    "  batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "  labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "  span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "  buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
    "  if data_index + span > len(data):\n",
    "      data_index = 0\n",
    "  buffer.extend(data[data_index:data_index + span])\n",
    "  data_index += span\n",
    "  for i in range(batch_size // num_skips):\n",
    "    context_words = [w for w in range(span) if w != skip_window]\n",
    "    words_to_use = random.sample(context_words, num_skips)\n",
    "    for j, context_word in enumerate(words_to_use):\n",
    "      if sentence_id_map[data_index-span+skip_window] == sentence_id_map[data_index-span+context_word]:\n",
    "        batch[i * num_skips + j] = buffer[skip_window]\n",
    "        labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "      else:\n",
    "        batch[i * num_skips + j] = 0\n",
    "        labels[i * num_skips + j, 0] = 0\n",
    "    if data_index == len(data):\n",
    "      buffer.extend(data[0:span])\n",
    "      data_index = span\n",
    "    else:\n",
    "      buffer.append(data[data_index])\n",
    "      data_index += 1\n",
    "  # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "  data_index = (data_index + len(data) - span) % len(data)\n",
    "  return batch, labels\n",
    "\n",
    "batch, labels = generate_batch(batch_size=20, num_skips=2, skip_window=2)\n",
    "print(input_data.title.head(2).values)\n",
    "for i in range(20):\n",
    "  print(batch[i], reverse_dictionary[batch[i]], '->', labels[i, 0], reverse_dictionary[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build and train a skip-gram model.\n",
    "\n",
    "batch_size = 128\n",
    "embedding_size = 64  # Dimension of the embedding vector.\n",
    "skip_window = 1  # How many words to consider left and right.\n",
    "num_skips = 2  # How many times to reuse an input to generate a label.\n",
    "num_sampled = 64  # Number of negative examples to sample.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent. These 3 variables are used only for\n",
    "# displaying model accuracy, they don't affect calculation.\n",
    "valid_size = 16  # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  with tf.name_scope('inputs'):\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    # Look up embeddings for inputs.\n",
    "  with tf.name_scope('embeddings'):\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "# Construct the variables for the NCE loss\n",
    "  with tf.name_scope('weights'):\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size))\n",
    "    )\n",
    "  with tf.name_scope('biases'):\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "  # Compute the average NCE loss for the batch.\n",
    "  # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "  # time we evaluate the loss.\n",
    "  # Explanation of the meaning of NCE loss:\n",
    "  #   http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "  with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(\n",
    "            weights=nce_weights,\n",
    "            biases=nce_biases,\n",
    "            labels=train_labels,\n",
    "            inputs=embed,\n",
    "            num_sampled=num_sampled,\n",
    "            num_classes=vocabulary_size))\n",
    "\n",
    "  # Add the loss value as a scalar to summary.\n",
    "  tf.summary.scalar('loss', loss)\n",
    "\n",
    "  # Construct the SGD optimizer\n",
    "  with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "  # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "  normalized_embeddings = embeddings / norm\n",
    "  valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,\n",
    "                                            valid_dataset)\n",
    "  similarity = tf.matmul(\n",
    "      valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "  # Merge all summaries.\n",
    "  merged = tf.summary.merge_all()\n",
    "\n",
    "  # Add variable initializer.\n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  # Create a saver.\n",
    "#   saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps to run: 425110\n",
      "Initialized\n",
      "Average loss at step 0 : 103.94065856933594\n",
      "Average loss at step 2000 : 41.379544763565065\n",
      "Average loss at step 4000 : 14.853939636468887\n",
      "Average loss at step 6000 : 8.718434990644456\n",
      "Average loss at step 8000 : 6.506455367326736\n",
      "Average loss at step 10000 : 5.465697678923607\n",
      "Average loss at step 12000 : 4.938184765577316\n",
      "Average loss at step 14000 : 4.644838224768638\n",
      "Average loss at step 16000 : 4.442403620481491\n",
      "Average loss at step 18000 : 4.306614495396614\n",
      "Average loss at step 20000 : 4.210343186855316\n",
      "Average loss at step 22000 : 4.138647977590561\n",
      "Average loss at step 24000 : 4.074294556975365\n",
      "Average loss at step 26000 : 4.029112906932831\n",
      "Average loss at step 28000 : 3.9827054071426393\n",
      "Average loss at step 30000 : 4.1763920413255695\n",
      "Average loss at step 32000 : 4.3512329577207565\n",
      "Average loss at step 34000 : 4.065875087141991\n",
      "Average loss at step 36000 : 3.8454126263856887\n",
      "Average loss at step 38000 : 3.7205225133895876\n",
      "Average loss at step 40000 : 3.6449291676282884\n",
      "Average loss at step 42000 : 3.597465677380562\n",
      "Average loss at step 44000 : 3.933728665947914\n",
      "Average loss at step 46000 : 3.9157315056324005\n",
      "Average loss at step 48000 : 3.853122591137886\n",
      "Average loss at step 50000 : 3.8344424426555634\n",
      "Average loss at step 52000 : 3.7990497814416884\n",
      "Average loss at step 54000 : 3.7825643883943556\n",
      "Average loss at step 56000 : 3.7673489451408386\n",
      "Average loss at step 58000 : 3.759575003862381\n",
      "Average loss at step 60000 : 3.745462715744972\n",
      "Average loss at step 62000 : 3.738304615736008\n",
      "Average loss at step 64000 : 3.733197044968605\n",
      "Average loss at step 66000 : 3.7181429438591005\n",
      "Average loss at step 68000 : 3.7115911297798156\n",
      "Average loss at step 70000 : 3.7045408440828322\n",
      "Average loss at step 72000 : 3.6981353180408476\n",
      "Average loss at step 74000 : 3.8031917535066606\n",
      "Average loss at step 76000 : 3.6629993847608566\n",
      "Average loss at step 78000 : 3.6637456110715867\n",
      "Average loss at step 80000 : 3.5084984496831892\n",
      "Average loss at step 82000 : 3.4753291417360304\n",
      "Average loss at step 84000 : 3.4578166394233705\n",
      "Average loss at step 86000 : 3.657185994744301\n",
      "Average loss at step 88000 : 3.781658835172653\n",
      "Average loss at step 90000 : 3.7170237547159193\n",
      "Average loss at step 92000 : 3.7074383630752563\n",
      "Average loss at step 94000 : 3.6799115674495697\n",
      "Average loss at step 96000 : 3.6711605448722837\n",
      "Average loss at step 98000 : 3.6596938486099244\n",
      "Average loss at step 100000 : 3.6593810176849364\n",
      "Average loss at step 102000 : 3.6457058809995653\n",
      "Average loss at step 104000 : 3.642985783815384\n",
      "Average loss at step 106000 : 3.646491170883179\n",
      "Average loss at step 108000 : 3.6316926844120028\n",
      "Average loss at step 110000 : 3.6369657254219057\n",
      "Average loss at step 112000 : 3.6243177261352537\n",
      "Average loss at step 114000 : 3.6161355652809144\n",
      "Average loss at step 116000 : 3.7041383501291274\n",
      "Average loss at step 118000 : 3.5322426657676695\n",
      "Average loss at step 120000 : 3.6366452057361602\n",
      "Average loss at step 122000 : 3.4473201160430906\n",
      "Average loss at step 124000 : 3.4108838179111483\n",
      "Average loss at step 126000 : 3.3984608597755432\n",
      "Average loss at step 128000 : 3.4865228506326678\n",
      "Average loss at step 130000 : 3.733793309688568\n",
      "Average loss at step 132000 : 3.660439145922661\n",
      "Average loss at step 134000 : 3.640478915929794\n",
      "Average loss at step 136000 : 3.6318674539327622\n",
      "Average loss at step 138000 : 3.6079591319561004\n",
      "Average loss at step 140000 : 3.604691016316414\n",
      "Average loss at step 142000 : 3.60817722594738\n",
      "Average loss at step 144000 : 3.591319086432457\n",
      "Average loss at step 146000 : 3.5917996250391004\n",
      "Average loss at step 148000 : 3.592920278072357\n",
      "Average loss at step 150000 : 3.586391517281532\n",
      "Average loss at step 152000 : 3.58197840821743\n",
      "Average loss at step 154000 : 3.5781122179031373\n",
      "Average loss at step 156000 : 3.574360784769058\n",
      "Average loss at step 158000 : 3.6429488316774368\n",
      "Average loss at step 160000 : 3.5121212397813797\n",
      "Average loss at step 162000 : 3.58475718832016\n",
      "Average loss at step 164000 : 3.4162176970243454\n",
      "Average loss at step 166000 : 3.373177763223648\n",
      "Average loss at step 168000 : 3.359343236088753\n",
      "Average loss at step 170000 : 3.3381910980939864\n",
      "Average loss at step 172000 : 3.7163491319417954\n",
      "Average loss at step 174000 : 3.626888419508934\n",
      "Average loss at step 176000 : 3.6003857988119123\n",
      "Average loss at step 178000 : 3.5929779554605483\n",
      "Average loss at step 180000 : 3.5715674250125886\n",
      "Average loss at step 182000 : 3.5644519321918486\n",
      "Average loss at step 184000 : 3.570675878405571\n",
      "Average loss at step 186000 : 3.5588109644651413\n",
      "Average loss at step 188000 : 3.553047158241272\n",
      "Average loss at step 190000 : 3.5584850461483\n",
      "Average loss at step 192000 : 3.5492011077404024\n",
      "Average loss at step 194000 : 3.5491067204475404\n",
      "Average loss at step 196000 : 3.547456503868103\n",
      "Average loss at step 198000 : 3.542153945684433\n",
      "Average loss at step 200000 : 3.5805290536880494\n",
      "Average loss at step 202000 : 3.523200874567032\n",
      "Average loss at step 204000 : 3.547191642999649\n",
      "Average loss at step 206000 : 3.407433675289154\n",
      "Average loss at step 208000 : 3.3535824650526047\n",
      "Average loss at step 210000 : 3.333559865474701\n",
      "Average loss at step 212000 : 3.321988682985306\n",
      "Average loss at step 214000 : 3.595392190337181\n",
      "Average loss at step 216000 : 3.609500835299492\n",
      "Average loss at step 218000 : 3.5661907131671904\n",
      "Average loss at step 220000 : 3.567234911441803\n",
      "Average loss at step 222000 : 3.5447963365316393\n",
      "Average loss at step 224000 : 3.5369578450918198\n",
      "Average loss at step 226000 : 3.5365392680168153\n",
      "Average loss at step 228000 : 3.534243394613266\n",
      "Average loss at step 230000 : 3.525307943582535\n",
      "Average loss at step 232000 : 3.5242814444303514\n",
      "Average loss at step 234000 : 3.5319431105852126\n",
      "Average loss at step 236000 : 3.517054400920868\n",
      "Average loss at step 238000 : 3.520689860224724\n",
      "Average loss at step 240000 : 3.5180112018585206\n",
      "Average loss at step 242000 : 3.5128563174009324\n",
      "Average loss at step 244000 : 3.5595363895893097\n",
      "Average loss at step 246000 : 3.4419631377458573\n",
      "Average loss at step 248000 : 3.475153284072876\n",
      "Average loss at step 250000 : 3.3347867826223374\n",
      "Average loss at step 252000 : 3.3192773028612135\n",
      "Average loss at step 254000 : 3.3162032524347307\n",
      "Average loss at step 256000 : 3.479130006313324\n",
      "Average loss at step 258000 : 3.5984104028940203\n",
      "Average loss at step 260000 : 3.5471127405166625\n",
      "Average loss at step 262000 : 3.5441659326553343\n",
      "Average loss at step 264000 : 3.5281221578121187\n",
      "Average loss at step 266000 : 3.5157609573602677\n",
      "Average loss at step 268000 : 3.5146648238897322\n",
      "Average loss at step 270000 : 3.515349185228348\n",
      "Average loss at step 272000 : 3.502263029575348\n",
      "Average loss at step 274000 : 3.5019535806179047\n",
      "Average loss at step 276000 : 3.5089526122808454\n",
      "Average loss at step 278000 : 3.499896523952484\n",
      "Average loss at step 280000 : 3.5050756026506424\n",
      "Average loss at step 282000 : 3.4958559465408325\n",
      "Average loss at step 284000 : 3.4899248555898668\n",
      "Average loss at step 286000 : 3.552832369089127\n",
      "Average loss at step 288000 : 3.3963865545988083\n",
      "Average loss at step 290000 : 3.4945481476783753\n",
      "Average loss at step 292000 : 3.333429974317551\n",
      "Average loss at step 294000 : 3.3039316157102583\n",
      "Average loss at step 296000 : 3.300938645839691\n",
      "Average loss at step 298000 : 3.372546772360802\n",
      "Average loss at step 300000 : 3.5995328431129456\n",
      "Average loss at step 302000 : 3.5335671470165253\n",
      "Average loss at step 304000 : 3.5233025598526\n",
      "Average loss at step 306000 : 3.5136366180181504\n",
      "Average loss at step 308000 : 3.4972066696882247\n",
      "Average loss at step 310000 : 3.492990594148636\n",
      "Average loss at step 312000 : 3.4993548282384874\n",
      "Average loss at step 314000 : 3.4819335927963255\n",
      "Average loss at step 316000 : 3.486816343903542\n",
      "Average loss at step 318000 : 3.490687432408333\n",
      "Average loss at step 320000 : 3.48467114841938\n",
      "Average loss at step 322000 : 3.4801556978225707\n",
      "Average loss at step 324000 : 3.48354625916481\n",
      "Average loss at step 326000 : 3.4748669437170028\n",
      "Average loss at step 328000 : 3.5351473180055617\n",
      "Average loss at step 330000 : 3.406876226902008\n",
      "Average loss at step 332000 : 3.4763724526166917\n",
      "Average loss at step 334000 : 3.3312094006538393\n",
      "Average loss at step 336000 : 3.292717809796333\n",
      "Average loss at step 338000 : 3.2827659232616426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 340000 : 3.2676215751171114\n",
      "Average loss at step 342000 : 3.6055637077093126\n",
      "Average loss at step 344000 : 3.5288439580202104\n",
      "Average loss at step 346000 : 3.504861311793327\n",
      "Average loss at step 348000 : 3.5032772285938263\n",
      "Average loss at step 350000 : 3.482249827504158\n",
      "Average loss at step 352000 : 3.4782127842903137\n",
      "Average loss at step 354000 : 3.483037461876869\n",
      "Average loss at step 356000 : 3.4742876183986664\n",
      "Average loss at step 358000 : 3.4681158018112184\n",
      "Average loss at step 360000 : 3.476936537861824\n",
      "Average loss at step 362000 : 3.4663966430425646\n",
      "Average loss at step 364000 : 3.4701143049001693\n",
      "Average loss at step 366000 : 3.465263208150864\n",
      "Average loss at step 368000 : 3.466487088918686\n",
      "Average loss at step 370000 : 3.4949755165576937\n",
      "Average loss at step 372000 : 3.4432626494169236\n",
      "Average loss at step 374000 : 3.455027218937874\n",
      "Average loss at step 376000 : 3.3416417183876037\n",
      "Average loss at step 378000 : 3.285819265842438\n",
      "Average loss at step 380000 : 3.273721978187561\n",
      "Average loss at step 382000 : 3.267117293357849\n",
      "Average loss at step 384000 : 3.5101309195756913\n",
      "Average loss at step 386000 : 3.527359201312065\n",
      "Average loss at step 388000 : 3.4894994897842406\n",
      "Average loss at step 390000 : 3.4934842368364336\n",
      "Average loss at step 392000 : 3.4747580959796904\n",
      "Average loss at step 394000 : 3.4635062158107757\n",
      "Average loss at step 396000 : 3.4682026314735412\n",
      "Average loss at step 398000 : 3.4629226310253145\n",
      "Average loss at step 400000 : 3.455478910684586\n",
      "Average loss at step 402000 : 3.455740924477577\n",
      "Average loss at step 404000 : 3.4627270032167434\n",
      "Average loss at step 406000 : 3.4507653958797455\n",
      "Average loss at step 408000 : 3.4597116285562515\n",
      "Average loss at step 410000 : 3.4503214223384857\n",
      "Average loss at step 412000 : 3.449484331011772\n",
      "Average loss at step 414000 : 3.487264508485794\n",
      "Average loss at step 416000 : 3.369381155848503\n",
      "Average loss at step 418000 : 3.413627242684364\n",
      "Average loss at step 420000 : 3.280460989713669\n",
      "Average loss at step 422000 : 3.268656039595604\n",
      "Average loss at step 424000 : 3.2656954485177994\n",
      "Nearest to air: wardah, stock, beige, giordani, clean, hydrating, terkini, lama\n",
      "Nearest to bioaqua: wardah, bibir, 20ml, temulawak, air, illuminating, blush, lasting\n",
      "Nearest to murah: rose, complete, facial, lt, hot, highlight, pixy, brightening\n",
      "Nearest to warna: flawless, colour, hitam, edition, jerawat, lama, april, melembabkan\n",
      "Nearest to white: gel, product, 8, brown, protection, dijual, tone, care\n",
      "Nearest to tint: high, baru, gloss, beige, gratis, serum, collection, lipcream\n",
      "Nearest to mineral: 10, with, zero, oriflame, chic, hn, secret, jordana\n",
      "Nearest to magic: loose, matt, purbasari, snow, ink, ponds, bagus, precious\n",
      "Nearest to nude: gel, brown, jerawat, UNK, finishing, 02, illuminating, bronzer\n",
      "Nearest to ready: laneige, fair, me, body, marcks, tea, silky, cc\n",
      "Nearest to skin: shade, with, spray, travel, hills, giordani, missha, sebum\n",
      "Nearest to promo: fair, di, asli, nyx, terbaru, red, house, peach\n",
      "Nearest to exclusive: intense, ori, velvet, soothing, tea, bayar, one, luminous\n",
      "Nearest to refill: ponds, nature, tea, matt, ii, green, botanica, travel\n",
      "Nearest to two: la, jordana, cosmetics, botanica, high, snow, kit, loose\n",
      "Nearest to termurah: blusher, novo, wardah, collection, 5, baru, terlaris, terbatas\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Begin training.\n",
    "data_index = 0\n",
    "\n",
    "num_epochs = 10\n",
    "num_steps = (len(data) * num_skips // batch_size + 1) * num_epochs\n",
    "print(\"Steps to run:\", num_steps)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "#   Open a writer to write summaries.\n",
    "#   writer = tf.summary.FileWriter(fp.log_dir, session.graph)\n",
    "\n",
    "  # We must initialize all variables before we use them.\n",
    "  init.run()\n",
    "  print('Initialized')\n",
    "\n",
    "  average_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batch_inputs, batch_labels = generate_batch(batch_size, num_skips,\n",
    "                                                skip_window)\n",
    "    feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "\n",
    "    # Define metadata variable.\n",
    "    run_metadata = tf.RunMetadata()\n",
    "\n",
    "    # We perform one update step by evaluating the optimizer op (including it\n",
    "    # in the list of returned values for session.run()\n",
    "    # Also, evaluate the merged op to get all summaries from the returned \"summary\" variable.\n",
    "    # Feed metadata variable to session for visualizing the graph in TensorBoard.\n",
    "    _, summary, loss_val = session.run(\n",
    "        [optimizer, merged, loss],\n",
    "        feed_dict=feed_dict,\n",
    "        run_metadata=run_metadata)\n",
    "    average_loss += loss_val\n",
    "\n",
    "    # Add returned summaries to writer in each step.\n",
    "#     writer.add_summary(summary, step)\n",
    "    # Add metadata to visualize the graph for the last run.\n",
    "#     if step == (num_steps - 1):\n",
    "#       writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "\n",
    "    if step % 2000 == 0:\n",
    "      if step > 0:\n",
    "        average_loss /= 2000\n",
    "      # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "      print('Average loss at step', step, ':', average_loss)\n",
    "      average_loss = 0\n",
    "\n",
    "    # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "#     if step % 10000 == 0:\n",
    "#       sim = similarity.eval()\n",
    "#       for i in range(valid_size):\n",
    "#         valid_word = reverse_dictionary[valid_examples[i]]\n",
    "#         top_k = 8  # number of nearest neighbors\n",
    "#         nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "#         log_str = 'Nearest to %s: %s' % (valid_word, \", \".join([reverse_dictionary[k] for k in nearest]))\n",
    "#         print(log_str)\n",
    "  \n",
    "  sim = similarity.eval()\n",
    "  for i in range(valid_size):\n",
    "    valid_word = reverse_dictionary[valid_examples[i]]\n",
    "    top_k = 8  # number of nearest neighbors\n",
    "    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "    log_str = 'Nearest to %s: %s' % (valid_word, \", \".join([reverse_dictionary[k] for k in nearest]))\n",
    "    print(log_str)\n",
    "  final_embeddings = normalized_embeddings.eval()\n",
    "\n",
    "  # Write corresponding labels for the embeddings.\n",
    "#   with open(fp.log_dir + '/metadata.tsv', 'w') as f:\n",
    "#     for i in range(vocabulary_size):\n",
    "#       f.write(reverse_dictionary[i] + '\\n')\n",
    "\n",
    "  # Save the model for checkpoints.\n",
    "#   saver.save(session, os.path.join(fp.log_dir, 'model.ckpt'))\n",
    "\n",
    "  # Create a configuration for visualizing embeddings with the labels in TensorBoard.\n",
    "#   config = projector.ProjectorConfig()\n",
    "#   embedding_conf = config.embeddings.add()\n",
    "#   embedding_conf.tensor_name = embeddings.name\n",
    "#   embedding_conf.metadata_path = os.path.join(fp.log_dir, 'metadata.tsv')\n",
    "#   projector.visualize_embeddings(writer, config)\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_title_vector(itemid, title):\n",
    "  tokens = title.split()\n",
    "  total_score = 0.0\n",
    "  total_vec = np.zeros(embedding_size)\n",
    "  for token in tokens:\n",
    "    if token not in known_word_set:\n",
    "      continue\n",
    "    word_vec = final_embeddings[dictionary[token]]\n",
    "    tf_idf_score = 1.0\n",
    "    total_score += tf_idf_score\n",
    "    total_vec += word_vec * tf_idf_score\n",
    "  \n",
    "  if total_score == 0.0:\n",
    "    return total_vec\n",
    "  return total_vec / total_score\n",
    "\n",
    "input_data[\"title_vector\"] = input_data.apply(lambda x: get_avg_title_vector(x.itemid, x.title), axis=1)\n",
    "validation_data[\"title_vector\"] = validation_data.apply(lambda x: get_avg_title_vector(x.itemid, x.title), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(guesses, correct, k):\n",
    "  for i in range(k):\n",
    "    if guesses[i] == correct:\n",
    "      return 1 / (i + 1), i + 1\n",
    "  return 0.0, 0\n",
    "\n",
    "def proba_to_guesses(probs, classes, k):\n",
    "  ret = list()\n",
    "  \n",
    "  for idx in np.argsort(probs)[-k:]:\n",
    "    ret.append(classes[idx])\n",
    "  \n",
    "  ret.reverse()\n",
    "  return ret\n",
    "\n",
    "def score_model(proba_vector, ground_truth, classes, k):\n",
    "  assert proba_vector.shape[1] == len(classes)\n",
    "  assert proba_vector.shape[0] == ground_truth.shape[0]\n",
    "  total_score = 0.0\n",
    "  \n",
    "  stat = [0] * (k + 1)\n",
    "  \n",
    "  for item_vec, correct in zip(proba_vector, ground_truth):\n",
    "    result, idx = map_at_k(proba_to_guesses(item_vec, classes, k), correct, k)\n",
    "    total_score += result\n",
    "    stat[idx] += 1\n",
    "  return total_score / proba_vector.shape[0], stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=64, random_state=12345)\n",
    "\n",
    "pca.fit(np.stack(np.concatenate((validation_data.image_vector.values, input_data.image_vector.values))))\n",
    "\n",
    "reduced_image_vector = pca.transform(np.stack(input_data.image_vector.values))\n",
    "\n",
    "input_data[\"image_vector_64\"] = np.vsplit(reduced_image_vector, indices_or_sections=reduced_image_vector.shape[0])\n",
    "\n",
    "validation_reduced_image_vector = pca.transform(np.stack(validation_data.image_vector.values))\n",
    "\n",
    "validation_data[\"image_vector_64\"] = np.vsplit(validation_reduced_image_vector,\n",
    "                                               indices_or_sections=validation_reduced_image_vector.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benefits (0.8762328284607256, [1685, 18775, 2252])\n",
      "Brand (0.891771301389997, [4681, 41998, 947])\n",
      "Colour_group (0.8065320420358542, [3238, 18114, 2913])\n"
     ]
    }
   ],
   "source": [
    "#dry run\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for y_col in input_data.columns.values[3:6]:\n",
    "  train, test = train_test_split(input_data[input_data[y_col] != -1], test_size=0.2, random_state=12345)\n",
    "  \n",
    "  if train[y_col].unique().shape[0] > 100:\n",
    "    significant = set(train[[y_col, \"itemid\"]].groupby(y_col).agg(\"count\")\\\n",
    "      .sort_values(\"itemid\", ascending=False).head(100).index.values)\n",
    "    train = train[train.apply(lambda x: x[y_col] in significant, axis=1)]\n",
    "    \n",
    "  clf = RandomForestClassifier(n_estimators=200, random_state=0, n_jobs=-1)\n",
    "  clf.fit(np.concatenate(\n",
    "    (np.stack(train.title_vector.values), np.stack(train.image_vector_64.values).reshape(-1, 64))\n",
    "    , axis=1), train[y_col])\n",
    "  \n",
    "  print(y_col, score_model(\n",
    "    clf.predict_proba(\n",
    "        np.concatenate(\n",
    "        (np.stack(test.title_vector.values), np.stack(test.image_vector_64.values).reshape(-1, 64))\n",
    "        , axis=1)\n",
    "      )\n",
    "      , test[y_col].values, clf.classes_, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benefits : training model...write to file...\n",
      "Brand : training model...write to file...\n",
      "Colour_group : training model...write to file...\n",
      "Product_texture : training model...write to file...\n",
      "Skin_type : training model...write to file...\n"
     ]
    }
   ],
   "source": [
    "# actual run - random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "with open(fp.csv_folder+\"submission/beauty_no_header.csv\", \"w\") as sub_file:\n",
    "  for y_col in input_data.columns.values[3:]:\n",
    "    try:\n",
    "      train, test = input_data[input_data[y_col] != -1], validation_data\n",
    "    except:\n",
    "      # there are vector feature fields after y columns\n",
    "      break\n",
    "\n",
    "    if train[y_col].unique().shape[0] > 100:\n",
    "      significant = set(train[[y_col, \"itemid\"]].groupby(y_col).agg(\"count\")\\\n",
    "        .sort_values(\"itemid\", ascending=False).head(100).index.values)\n",
    "      train = train[train.apply(lambda x: x[y_col] in significant, axis=1)]\n",
    "    \n",
    "    print(y_col, \": training model...\", end=\"\")\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=0, n_jobs=-1)\n",
    "    clf.fit(np.concatenate(\n",
    "      (np.stack(train.title_vector.values), np.stack(train.image_vector_64.values).reshape(-1, 64))\n",
    "      , axis=1), train[y_col])\n",
    "\n",
    "    proba_vector = clf.predict_proba(\n",
    "          np.concatenate(\n",
    "          (np.stack(test.title_vector.values), np.stack(test.image_vector_64.values).reshape(-1, 64))\n",
    "          , axis=1)\n",
    "        )\n",
    "    assert validation_data.itemid.values.shape[0] == proba_vector.shape[0]\n",
    "    \n",
    "    print(\"write to file...\")\n",
    "\n",
    "    for itemid, item_vec in zip(validation_data.itemid.values, proba_vector):\n",
    "      guesses = proba_to_guesses(item_vec, clf.classes_, 2)\n",
    "      sub_file.write(f\"{itemid}_{y_col},{' '.join([str(g) for g in guesses])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benefits : training model...Epoch 1/10\n",
      "113556/113556 [==============================] - 12s 109us/step - loss: 1.2852 - acc: 0.5020\n",
      "Epoch 2/10\n",
      "113556/113556 [==============================] - 10s 91us/step - loss: 0.8417 - acc: 0.6711\n",
      "Epoch 3/10\n",
      "113556/113556 [==============================] - 11s 95us/step - loss: 0.7544 - acc: 0.7045\n",
      "Epoch 4/10\n",
      "113556/113556 [==============================] - 12s 103us/step - loss: 0.7208 - acc: 0.7172\n",
      "Epoch 5/10\n",
      "113556/113556 [==============================] - 11s 98us/step - loss: 0.7035 - acc: 0.7245\n",
      "Epoch 6/10\n",
      "113556/113556 [==============================] - 11s 95us/step - loss: 0.6925 - acc: 0.7296\n",
      "Epoch 7/10\n",
      "113556/113556 [==============================] - 11s 96us/step - loss: 0.6809 - acc: 0.7332\n",
      "Epoch 8/10\n",
      "113556/113556 [==============================] - 11s 97us/step - loss: 0.6737 - acc: 0.7376\n",
      "Epoch 9/10\n",
      "113556/113556 [==============================] - 11s 96us/step - loss: 0.6683 - acc: 0.7395\n",
      "Epoch 10/10\n",
      "113556/113556 [==============================] - 11s 96us/step - loss: 0.6636 - acc: 0.7431\n",
      "predicting...write to file...\n",
      "Brand : training model...Epoch 1/10\n",
      "226931/226931 [==============================] - 22s 97us/step - loss: 1.9134 - acc: 0.5573\n",
      "Epoch 2/10\n",
      "226931/226931 [==============================] - 23s 100us/step - loss: 0.8107 - acc: 0.8036\n",
      "Epoch 3/10\n",
      "226931/226931 [==============================] - 21s 94us/step - loss: 0.6807 - acc: 0.8367\n",
      "Epoch 4/10\n",
      "226931/226931 [==============================] - 22s 95us/step - loss: 0.6332 - acc: 0.8476\n",
      "Epoch 5/10\n",
      "226931/226931 [==============================] - 22s 96us/step - loss: 0.6010 - acc: 0.8559\n",
      "Epoch 6/10\n",
      "226931/226931 [==============================] - 22s 96us/step - loss: 0.5808 - acc: 0.8604\n",
      "Epoch 7/10\n",
      "226931/226931 [==============================] - 22s 98us/step - loss: 0.5626 - acc: 0.8651\n",
      "Epoch 8/10\n",
      "226931/226931 [==============================] - 22s 96us/step - loss: 0.5536 - acc: 0.8672\n",
      "Epoch 9/10\n",
      "226931/226931 [==============================] - 21s 94us/step - loss: 0.5441 - acc: 0.8697\n",
      "Epoch 10/10\n",
      "226931/226931 [==============================] - 22s 95us/step - loss: 0.5356 - acc: 0.8716\n",
      "predicting...write to file...\n",
      "Colour_group : training model...Epoch 1/10\n",
      "121324/121324 [==============================] - 12s 98us/step - loss: 2.0564 - acc: 0.3947\n",
      "Epoch 2/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.4757 - acc: 0.5652\n",
      "Epoch 3/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.2904 - acc: 0.6251\n",
      "Epoch 4/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.2244 - acc: 0.6448\n",
      "Epoch 5/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.1878 - acc: 0.6547\n",
      "Epoch 6/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.1631 - acc: 0.6619\n",
      "Epoch 7/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.1442 - acc: 0.6662\n",
      "Epoch 8/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.1333 - acc: 0.6699\n",
      "Epoch 9/10\n",
      "121324/121324 [==============================] - 12s 96us/step - loss: 1.1177 - acc: 0.6748\n",
      "Epoch 10/10\n",
      "121324/121324 [==============================] - 12s 100us/step - loss: 1.1067 - acc: 0.6783\n",
      "predicting...write to file...\n",
      "Product_texture : training model...Epoch 1/10\n",
      "244295/244295 [==============================] - 24s 98us/step - loss: 0.4459 - acc: 0.8605\n",
      "Epoch 2/10\n",
      "244295/244295 [==============================] - 24s 96us/step - loss: 0.1955 - acc: 0.9419\n",
      "Epoch 3/10\n",
      "244295/244295 [==============================] - 24s 96us/step - loss: 0.1765 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "244295/244295 [==============================] - 24s 96us/step - loss: 0.1695 - acc: 0.9494\n",
      "Epoch 5/10\n",
      "244295/244295 [==============================] - 24s 98us/step - loss: 0.1634 - acc: 0.9509\n",
      "Epoch 6/10\n",
      "244295/244295 [==============================] - 24s 96us/step - loss: 0.1600 - acc: 0.9522\n",
      "Epoch 7/10\n",
      "244295/244295 [==============================] - 24s 96us/step - loss: 0.1560 - acc: 0.9536\n",
      "Epoch 8/10\n",
      "244295/244295 [==============================] - 24s 96us/step - loss: 0.1544 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "244295/244295 [==============================] - 24s 97us/step - loss: 0.1515 - acc: 0.9549\n",
      "Epoch 10/10\n",
      "244295/244295 [==============================] - 24s 97us/step - loss: 0.1513 - acc: 0.9556\n",
      "predicting...write to file...\n",
      "Skin_type : training model...Epoch 1/10\n",
      "58410/58410 [==============================] - 6s 102us/step - loss: 1.7495 - acc: 0.4044\n",
      "Epoch 2/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.3493 - acc: 0.5253\n",
      "Epoch 3/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.2459 - acc: 0.5665\n",
      "Epoch 4/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.1918 - acc: 0.5872\n",
      "Epoch 5/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.1574 - acc: 0.6031\n",
      "Epoch 6/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.1373 - acc: 0.6103\n",
      "Epoch 7/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.1212 - acc: 0.6140\n",
      "Epoch 8/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.1063 - acc: 0.6178\n",
      "Epoch 9/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.0978 - acc: 0.6231\n",
      "Epoch 10/10\n",
      "58410/58410 [==============================] - 6s 96us/step - loss: 1.0903 - acc: 0.6243\n",
      "predicting...write to file...\n"
     ]
    }
   ],
   "source": [
    "# actual run - neural network\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "with open(fp.csv_folder+\"submission/beauty_no_header.csv\", \"w\") as sub_file:\n",
    "  for y_col in input_data.columns.values[3:]:\n",
    "    try:\n",
    "      train, test = input_data[input_data[y_col] != -1], validation_data\n",
    "    except:\n",
    "      # there are vector feature fields after y columns\n",
    "      break\n",
    "\n",
    "    if train[y_col].unique().shape[0] > 100:\n",
    "      significant = set(train[[y_col, \"itemid\"]].groupby(y_col).agg(\"count\")\\\n",
    "        .sort_values(\"itemid\", ascending=False).head(100).index.values)\n",
    "      train = train[train.apply(lambda x: x[y_col] in significant, axis=1)]\n",
    "    \n",
    "    print(y_col, \": training model...\", end=\"\")\n",
    "    \n",
    "    labels = train[y_col].unique()\n",
    "    labels.sort()\n",
    "\n",
    "    input_size = train.title_vector.head(1).values[0].shape[0] + train.image_vector_64.head(1).values[0].shape[1]\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(128, input_shape=(input_size,)),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Activation('relu'),\n",
    "      tf.keras.layers.Dense(labels.shape[0]),\n",
    "      tf.keras.layers.Activation('softmax'),\n",
    "    ])\n",
    "\n",
    "    optim = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    enc = OneHotEncoder(categories=[labels], sparse=False)\n",
    "\n",
    "    model.fit(np.concatenate(\n",
    "      (np.stack(train.title_vector.values), np.stack(train.image_vector_64.values).reshape(-1, 64))\n",
    "      , axis=1)\n",
    "      , enc.fit_transform(train[y_col].values.reshape(-1, 1)), epochs=10, batch_size=32)\n",
    "    \n",
    "    print(\"predicting...\", end=\"\")\n",
    "    proba_vector = model.predict(\n",
    "          np.concatenate(\n",
    "          (np.stack(test.title_vector.values), np.stack(test.image_vector_64.values).reshape(-1, 64))\n",
    "          , axis=1)\n",
    "        )\n",
    "    assert validation_data.itemid.values.shape[0] == proba_vector.shape[0]\n",
    "    \n",
    "    print(\"write to file...\")\n",
    "\n",
    "    for itemid, item_vec in zip(validation_data.itemid.values, proba_vector):\n",
    "      guesses = proba_to_guesses(item_vec, labels, 2)\n",
    "      sub_file.write(f\"{itemid}_{y_col},{' '.join([str(g) for g in guesses])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benefits : training model...predicting...write to file...\n",
      "Brand : training model...predicting...write to file...\n",
      "Colour_group : training model...predicting...write to file...\n",
      "Product_texture : training model...predicting...write to file...\n",
      "Skin_type : training model...predicting...write to file...\n"
     ]
    }
   ],
   "source": [
    "# actual run - xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "with open(fp.csv_folder+\"submission/beauty_no_header.csv\", \"w\") as sub_file:\n",
    "  for y_col in input_data.columns.values[3:]:\n",
    "    try:\n",
    "      train, test = input_data[input_data[y_col] != -1], validation_data\n",
    "    except:\n",
    "      # there are vector feature fields after y columns\n",
    "      break\n",
    "\n",
    "    if train[y_col].unique().shape[0] > 100:\n",
    "      significant = set(train[[y_col, \"itemid\"]].groupby(y_col).agg(\"count\")\\\n",
    "        .sort_values(\"itemid\", ascending=False).head(100).index.values)\n",
    "      train = train[train.apply(lambda x: x[y_col] in significant, axis=1)]\n",
    "    \n",
    "    print(y_col, \": training model...\", end=\"\")\n",
    "    \n",
    "    clf = xgb.XGBClassifier(n_estimators=120, random_state=123, n_jobs=6, max_depth=6, gpu_id=0, max_bin=16, tree_method='gpu_hist')\n",
    "    clf.fit(np.concatenate(\n",
    "      (np.stack(train.title_vector.values), np.stack(train.image_vector_64.values).reshape(-1, 64))\n",
    "      , axis=1), train[y_col])\n",
    "    \n",
    "    print(\"predicting...\", end=\"\")\n",
    "    proba_vector = clf.predict_proba(\n",
    "          np.concatenate(\n",
    "          (np.stack(test.title_vector.values), np.stack(test.image_vector_64.values).reshape(-1, 64))\n",
    "          , axis=1)\n",
    "        )\n",
    "    assert validation_data.itemid.values.shape[0] == proba_vector.shape[0]\n",
    "    \n",
    "    print(\"write to file...\")\n",
    "\n",
    "    for itemid, item_vec in zip(validation_data.itemid.values, proba_vector):\n",
    "      guesses = proba_to_guesses(item_vec, clf.classes_, 2)\n",
    "      sub_file.write(f\"{itemid}_{y_col},{' '.join([str(g) for g in guesses])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
